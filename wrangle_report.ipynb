{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs - Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per instructions.\n",
    "\n",
    "- downloaded twitter-archive-enhanced.csv.\n",
    "- Created twitter developer account \n",
    "- Created tweet_json.txt by using dataframe scraped from twitter API. \n",
    "- Downloaded the file image predictions in tsv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Assesing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below, each column of each table in this twitter dataset is described. \n",
    "To see the table that goes hand in hand with these descriptions, I displayed each table in its entirety by displaying the pandas DataFrame that it was gathered into. \n",
    "This task is the mechanical part of visual assessment in pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.`Enhanced Twitter Archive`\n",
    "\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which  used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, we have filtered for tweets with ratings only (there are 2356).\n",
    "\n",
    "`archive_df` columns and their description:\n",
    "    \n",
    "- **tweet_id**: the unique identifier for each of the tweet\n",
    "- **in_reply_to_status_id**: the status id for the reply given to the tweet id\n",
    "- **in_reply_to_user_id**: the status id for the reply given to the tweet id ( w.r.t user id)\n",
    "- **timestamp**: Date and time the tweet was created, in Excel-friendly format.\n",
    "- **source**: the web link as source\n",
    "- **text**: the corresponding tweets text\n",
    "- **retweeted_status_id**: the status id for the reply given to the tweet id i.e., for the retweeted id\n",
    "- **retweeted_status_user_id**: the status id for the reply given to the tweet id ( w.r.t user id) i.e., for the retweeted id\n",
    "- **retweeted_status_timestamp**: Date and time the tweet was created, in Excel-friendly format.\n",
    "- **expanded_urls**: Expanded version of url1; URL entered by user and displayed in Twitter. Note that the user-entered URL may itself be a shortened URL, e.g. from bit.ly.\n",
    "- **rating_numerator**: the ranking given by the user\n",
    "- **rating_denominator**: The reference ranking given by the user \n",
    "- **name**: the breed or dog's name\n",
    "- **doggo**, **floofer**,  **pupper**, **puppo** -- The stage of the dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `Tweets_info_df`\n",
    "\n",
    "Columns and their description:\n",
    "\n",
    "- **tweet_id**: The unique identifier for each of the tweet\n",
    "- **retweets**: The count of retweets done by user\n",
    "- **favorites**: The count of favorites done by user\n",
    "- **followers**: The count of number of followers\n",
    "- **friends**: The count of number of friends\n",
    "\n",
    "\n",
    "#### `Quality - tweets_info_df` table\n",
    "\n",
    "- 14 tweet ids information is Missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. `Quality - image_predictions_df :`\n",
    "\n",
    "Columns and their description:\n",
    "    \n",
    "- **tweet_id**: tweet_id is the last part of the tweet URL after \"status/\"\n",
    "- **jpg_url**: Image link or URL\n",
    "- **img_num**: Image number\n",
    "- **p1**: p1 is the algorithm's #1 prediction for the image in the tweet \n",
    "- **p1_conf**: p1_conf is how confident the algorithm is in its #1 prediction\n",
    "- **p1_dog**: p1_dog is whether or not the #1 prediction is a breed of dog\n",
    "- **p2**: is the algorithm's second most likely prediction\n",
    "- **p2_conf**: is how confident the algorithm is in its #2 prediction\n",
    "- **p2_dog**:  is whether or not the #2 prediction is a breed of dog \n",
    "- **p3**: p3 is the algorithm's #3 prediction for the image in the tweet\n",
    "- **p3_conf**: p3_conf is how confident the algorithm is in its #3 prediction\n",
    "- **p3_dog**: p3_dog is whether or not the #3 prediction is a breed of dog\n",
    "\n",
    "`Quality - image_predictions_df` table:\n",
    "\n",
    "- only 2075 tweetIds have images\n",
    "- Aalysis  of twitter archived data is 2356 so, there is missing image data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Observations\n",
    "\n",
    "1. in_reply_to_status_id only 78 non null values.\n",
    "2. in_reply_to_user_id data only 78 non null values.\n",
    "3. timestamp data type is in string format .\n",
    "4. retweeted_status_id  only 181 non null values.\n",
    "5. retweeted_status_user_id only 181 id retweeted\n",
    "6. retweeted_status_timestamp datatype is in string format .\n",
    "7. expanded_urls data missing.total url: 2297 non null values\n",
    "8. source field contains url inside html statement\n",
    "9.  Some Tweets rating of denominator of 0\n",
    "10. Looking at the data set we can see there are random data names in the tweet data base. Etracted dog name contain invalid name such as :a,an ,the,very, etc. Such dog tweets may be dropped as such but I chose to keep the tweets.  Which can be manually removed. But I have chosen to keep the tweets as we just need the retweet and favorite count from the tweet. Name of the dogs dosent matter.\n",
    "11. Timestamp data type is in string format .\n",
    "12. Datatype errors were present\n",
    "13. Extract url from source html tag\n",
    "14. None values in dog type(stage) fields\n",
    "15. Image URL are html statements\n",
    "16. Combined dog stages into one coloumn using melt function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the three datasets were stored into respective csv/tsv/json files and read into ipython notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
